{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a44cb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b06d45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"data/A - AmbulanceCalls.xlsx\"\n",
    "\n",
    "ambulance_train_df = pd.read_excel(filepath, sheet_name='train')\n",
    "ambulance_test_df = pd.read_excel(filepath, sheet_name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975d7f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", None):\n",
    "    print(ambulance_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5732720",
   "metadata": {},
   "outputs": [],
   "source": [
    "ambulance_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098b35a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train shape: {ambulance_train_df.shape}\")\n",
    "print(f\"Test shape: {ambulance_test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41e4e94",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "1.   Does the data contain any trends? How do you know?\n",
    "2.   Does the data contain seasonality? How do you know?\n",
    "    *Cant use: Dickey-Fuller test, Augmented Dickey-Fuller test, KPSS test\n",
    "\n",
    "3. Were there any major outliers (i.e., large upward or downward spikes)? Should they be included in the forecasting analysis or not? Why?\n",
    "\n",
    "4. Through your data analysis, determine what type of forecasting methods would be appropriate for use in forecasting future values for the selected dataset.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5603095c",
   "metadata": {},
   "source": [
    "#### 1. Trend Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ca0255",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(ambulance_train_df[\"date\"], ambulance_train_df[\"calls\"])\n",
    "plt.title(\"Train Data: Ambulance Calls\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"# of Calls\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db09256",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_windows = [5,26,52]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "for window in ma_windows:\n",
    "    ma_series = ambulance_train_df['calls'].rolling(window=window, center=True).mean()\n",
    "    ax.plot(ambulance_train_df[\"date\"], ma_series, label=f\"MA Window Size: {window} weeks\")\n",
    "\n",
    "ax.set_title(\"Train Data: Smoothed Ambulance Calls w MA\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"# of Calls\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119824c8",
   "metadata": {},
   "source": [
    "When we plot the original ambulance call data, we observe clear cycles, but it is difficult to identify any longer term trends. We do notice that the third peak appears slightly broader than the first two suggesting a possible trend.\n",
    "\n",
    "To better visualize the data and reduce noise, we apply moving averages (MA). Considering the cycles in the data, we looked at typical time frames: each month has approximately 3–5 data points (weeks), while each year has roughly 51–52 data points.\n",
    "\n",
    "Using these as our sliding windows, we apply MA with windows of 5 (roughly a month) and 52 (roughly a year). We observe that as the MA window increases, the fluctuations smooth out and the underlying trend becomes more apparent. In particular, the yearly MA reveals a gradual upward trend, confirming that a long-term trend exists in the data once seasonality is smoothed out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf92800",
   "metadata": {},
   "source": [
    "#### 2. Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6989b69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "plot_acf(ambulance_train_df['calls'], lags=104) # Compute autocorr for evry lag up to 104\n",
    "plt.title(\"Autocorrelation of Ambulance Calls\")\n",
    "plt.xlabel(\"Lag (by num of data points)\")\n",
    "plt.ylabel(\"Autocorrelation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f02d5e",
   "metadata": {},
   "source": [
    "When plotting the raw training data, we can clearly identify cycles, notably: the first cycle from 2020-01 to 2021-01, the second cycle from 2021-01 to 2022-05, and the last cycle from 2022-05 to 2023-05.\n",
    "\n",
    "To further verify the presence of seasonality, we plot the autocorrelation function (ACF) of the data. From the ACF, we observe that the series exhibits weak autocorrelation with its lagged values, with the strongest correlation of approximately 0.3 at a lag of ~53, which corresponds to roughly one year’s worth of data points, consistent with the cycles identified in the time series. The weak autocorrelation can be the result of the noisy data so to further explore we can retry the acf on the smmothed data (via MA) to find stronger correlation\n",
    "\n",
    "Also a decay suggests non-stationary (ex: trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6837a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "for window in ma_windows:\n",
    "    ma_series = ambulance_train_df['calls'].rolling(window=window, center=True).mean().dropna()\n",
    "    plot_acf(ma_series, lags=104) # Compute autocorr for evry lag up to 104\n",
    "    plt.title(f\"Autocorrelation of Ambulance Calls w/ MA Window Size:{window}\")\n",
    "    plt.xlabel(\"Lag (by num of data points)\")\n",
    "    plt.ylabel(\"Autocorrelation\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31c2cfc",
   "metadata": {},
   "source": [
    "#### 3. Outlier Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf22262",
   "metadata": {},
   "source": [
    "#### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f89224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "decomposition = seasonal_decompose(ambulance_train_df['calls'], model='additive', period=52)\n",
    "residuals = decomposition.resid.dropna()\n",
    "residuals.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bded364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Std and mean\n",
    "resid_mean = residuals.mean()\n",
    "resid_std = residuals.std()\n",
    "lower_bound = resid_mean - 3 * resid_std\n",
    "upper_bound = resid_mean + 3 * resid_std\n",
    "\n",
    "outliers = residuals[(residuals < lower_bound) | (residuals > upper_bound)]\n",
    "print(f\"Outliers found through stdeva: {outliers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5c1a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantiles\n",
    "Q1 = residuals.quantile(0.25)\n",
    "Q3 = residuals.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "robust_lower = Q1 - 1.5 * IQR\n",
    "robust_upper = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers_iqr = residuals[(residuals < robust_lower) | (residuals > robust_upper)]\n",
    "\n",
    "print(\"Outliers found using Robust IQR:\")\n",
    "print(outliers_iqr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc9d18d",
   "metadata": {},
   "source": [
    "The difference between the two methods highlights a statistical property known as \"masking.\" The stdeva method failed to detect any outliers because the extreme spike on September 19 2022 was large enough to inflate the entire datasets stdeva. This inflated value widened the upper boundary significantly that the outlier was effectively hidden within the expanded definition of \"normal.\" \n",
    "\n",
    "The IQR method is robust to extreme values because it constructs boundaries based on the middle 50% of the data. By ignoring the extremes during calculation, the IQR method correctly identified the residual of approximately 207 as a statistically significant anomaly that the standard deviation method missed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041bff05",
   "metadata": {},
   "source": [
    "### Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7f453a",
   "metadata": {},
   "source": [
    "#### 1. Triple Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2a0d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "model = ExponentialSmoothing(\n",
    "    ambulance_train_df['calls'], \n",
    "    trend='add', \n",
    "    seasonal='add', \n",
    "    seasonal_periods=52\n",
    ")\n",
    "\n",
    "fitted_model = model.fit()\n",
    "\n",
    "forecast_steps = len(ambulance_test_df)\n",
    "forecast = fitted_model.forecast(steps=forecast_steps)\n",
    "forecast.index = ambulance_test_df['date']\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(ambulance_train_df['date'], ambulance_train_df['calls'], label='Actual Data', color='blue')\n",
    "plt.plot(ambulance_train_df['date'], fitted_model.fittedvalues, label='Model Fit (Training)', color='orange', alpha=0.7)\n",
    "plt.plot(forecast.index, forecast, label='Forecast (Next 6 Months)', color='red', linestyle='--')\n",
    "plt.title('Triple Exponential Smoothing (Winters) Forecast')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Ambulance Calls')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a683049",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fitted_model.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c5cd08",
   "metadata": {},
   "source": [
    "The TES Winters model optimized to a smoothing level of 0.37, indicating moderate responsiveness to recent changes. Notably, both trend and seasonal smoothing were 0.0, indicating that the underlying seasonal structure (Winter Lows/Summer Highs) is highly stable and does not evolve significantly over time. The seasonal factors confirm this, showing that peak summer weeks consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5674becf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mape = mean_absolute_error(ambulance_train_df['calls'], fitted_model.fittedvalues)\n",
    "print(\"MAE on fitted training data:\", mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb11f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df = pd.DataFrame(index=['Training', 'Test'])\n",
    "error_df.loc[\"Training\", \"TES\"] = 63.00824924211579"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c18721",
   "metadata": {},
   "source": [
    "##### Sensitivty Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b256ee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forecast(alpha, beta, gamma):\n",
    "    model = ExponentialSmoothing(\n",
    "        ambulance_train_df['calls'], \n",
    "        trend='add', \n",
    "        seasonal='mul', \n",
    "        seasonal_periods=52\n",
    "    )\n",
    "\n",
    "    fitted_model = model.fit(\n",
    "        smoothing_level=alpha, \n",
    "        smoothing_trend=beta, \n",
    "        smoothing_seasonal=gamma, \n",
    "        optimized=False\n",
    "    )\n",
    "    \n",
    "    return fitted_model.forecast(30)\n",
    "\n",
    "base_alpha = 0.344\n",
    "base_beta  = 0.0\n",
    "base_gamma = 0.0\n",
    "\n",
    "# Scenario 1: Base Case \n",
    "forecast_base = get_forecast(base_alpha, base_beta, base_gamma)\n",
    "\n",
    "# Scenario 2: Sensitivity to Level (Alpha +- 10%)\n",
    "forecast_alpha_high = get_forecast(base_alpha * 1.5, base_beta, base_gamma)\n",
    "forecast_alpha_low  = get_forecast(base_alpha * 0.5, base_beta, base_gamma)\n",
    "\n",
    "# Scenario 3: Sensitivity to Trend (Force Beta = 0.05)\n",
    "forecast_beta_forced = get_forecast(base_alpha, 0.05, base_gamma)\n",
    "\n",
    "# Scenario 4: Sensitivity to Seasonality (Force Gamma = 0.05)\n",
    "forecast_gamma_forced = get_forecast(base_alpha, base_beta, 0.05)\n",
    "\n",
    "# Impact\n",
    "diff_alpha = np.mean(np.abs(forecast_base - forecast_alpha_high))\n",
    "diff_beta  = np.mean(np.abs(forecast_base - forecast_beta_forced))\n",
    "diff_gamma = np.mean(np.abs(forecast_base - forecast_gamma_forced))\n",
    "\n",
    "print(\"Sensitivity Report (Avg Change in 30-Week Forecast):\")\n",
    "print(f\"1. Adjusting Alpha by 50%:   {diff_alpha:.2f} calls/week\")\n",
    "print(f\"2. Forcing Trend (Beta=0.05): {diff_beta:.2f} calls/week\")\n",
    "print(f\"3. Forcing Season (Gamma=0.05): {diff_gamma:.2f} calls/week\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(ambulance_train_df['date'].iloc[-52:], ambulance_train_df['calls'].iloc[-52:], label='Historical Data (Last 52 Weeks)', color='gray', alpha=0.5)\n",
    "plt.plot(ambulance_test_df['date'], forecast_base, label='Base Model (Beta=0, Gamma=0)', color='black', linewidth=2.5)\n",
    "plt.plot(ambulance_test_df['date'], forecast_alpha_high, label='Alpha +50%', color='blue', linestyle='--')\n",
    "plt.plot(ambulance_test_df['date'], forecast_alpha_low, label='Alpha -50%', color='pink', linestyle='--')\n",
    "plt.plot(ambulance_test_df['date'], forecast_beta_forced, label='Force Trend (Beta=0.05)', color='red', linestyle=':')\n",
    "plt.plot(ambulance_test_df['date'], forecast_gamma_forced, label='Force Season (Gamma=0.05)', color='green', linestyle=':')\n",
    "plt.title(\"Sensitivity Analysis: How Parameters Impact the Forecast\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Calls\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc65d22a",
   "metadata": {},
   "source": [
    "#### 2. ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ecf79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# First Difference -> d=1\n",
    "diff_series = ambulance_train_df['calls'].diff().dropna()\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(diff_series)\n",
    "plt.title(\"First Differenced Series (d=1)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# PACF -> p\n",
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "plot_pacf(diff_series, lags=20, method='ywm', ax=ax)\n",
    "ax.set_xlim(0, 20)\n",
    "ax.set_xticks(np.arange(0, 21, 1))\n",
    "ax.grid(True, axis='both')\n",
    "ax.set_xlabel(\"Lag\")\n",
    "ax.set_ylabel(\"Partial Autocorrelation\")\n",
    "ax.set_title(\"PACF Plot (Use this to choose p)\")\n",
    "plt.show()\n",
    "\n",
    "# ACF -> q\n",
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "plot_acf(diff_series, lags=20, ax=ax)\n",
    "ax.set_xlim(0, 20)\n",
    "ax.set_xticks(np.arange(0, 21, 1))\n",
    "ax.grid(True, axis='both')\n",
    "ax.set_xlabel(\"Lag\")\n",
    "ax.set_ylabel(\"Autocorrelation\")\n",
    "ax.set_title(\"ACF Plot (Use this to choose q)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86419a82",
   "metadata": {},
   "source": [
    "We choose p = 2 and q = 1 and d = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9d7b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "arima_model = ARIMA(ambulance_train_df['calls'], order=(2, 1, 1))\n",
    "arima_fitted = arima_model.fit()\n",
    "forecast_arima = arima_fitted.forecast(steps=30)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(ambulance_train_df['calls'], label='Observed', color=\"blue\")\n",
    "plt.plot(arima_fitted.fittedvalues, label='Fitted', color=\"orange\")\n",
    "plt.plot(forecast_arima, label='Forecast', color=\"red\", linestyle= '--')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(arima_fitted.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a194afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(ambulance_train_df['calls'], arima_fitted.fittedvalues)\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b3c5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df.loc[\"Training\", \"ARIMA\"] = 79.65246552845532"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f877d13",
   "metadata": {},
   "source": [
    "#### Sensitivty Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c113d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "def get_arima_forecast(order):\n",
    "    model = ARIMA(ambulance_train_df['calls'], order=order)\n",
    "    res = model.fit()\n",
    "    return res.forecast(steps=30)\n",
    "\n",
    "# Base Case: Your winner\n",
    "base_order = (2, 1, 1)\n",
    "forecast_base = get_arima_forecast(base_order)\n",
    "\n",
    "# Scenario 1: Sensitivity to AR Term \n",
    "forecast_p_low = get_arima_forecast((1, 1, 1))\n",
    "forecast_p_high = get_arima_forecast((3, 1, 1))\n",
    "\n",
    "# Scenario 2: Sensitivity to MA Term \n",
    "forecast_q_low = get_arima_forecast((2, 1, 0))\n",
    "forecast_q_high = get_arima_forecast((2, 1, 2))\n",
    "\n",
    "diff_p_low  = np.mean(np.abs(forecast_base - forecast_p_low))\n",
    "diff_p_high = np.mean(np.abs(forecast_base - forecast_p_high))\n",
    "diff_q_low  = np.mean(np.abs(forecast_base - forecast_q_low))\n",
    "diff_q_high = np.mean(np.abs(forecast_base - forecast_q_high))\n",
    "\n",
    "print(\"ARIMA Sensitivity Report (Avg Change in 30-Week Forecast):\")\n",
    "print(f\"1. Reducing AR (p=1):    {diff_p_low:.2f} calls/week\")\n",
    "print(f\"2. Increasing AR (p=3):  {diff_p_high:.2f} calls/week\")\n",
    "print(f\"3. Removing MA (q=0):    {diff_q_low:.2f} calls/week\")\n",
    "print(f\"2. Increasing MA (q=2):    {diff_q_high:.2f} calls/week\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(ambulance_train_df['date'].iloc[-52:], ambulance_train_df['calls'].iloc[-52:], label='Historical Data (Last 52 Weeks)', color='gray', alpha=0.5)\n",
    "plt.plot(ambulance_test_df['date'], forecast_base, label='Base Model (2,1,1)', color='black', linewidth=2.5)\n",
    "plt.plot(ambulance_test_df['date'], forecast_p_low, label='Reduce AR (1,1,1)', color='blue', linestyle='--')\n",
    "plt.plot(ambulance_test_df['date'], forecast_p_high, label='Increase AR (3,1,1)', color='pink', linestyle=':')\n",
    "plt.plot(ambulance_test_df['date'], forecast_q_low, label='Remove MA (2,1,0)', color='red', linestyle=':')\n",
    "plt.plot(ambulance_test_df['date'], forecast_q_high, label='Remove MA (2,1,2)', color='green', linestyle=':')\n",
    "plt.title(\"ARIMA Sensitivity Analysis: Structural Changes (Model Orders)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Calls\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce36a257",
   "metadata": {},
   "source": [
    "#### Grid Search with SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7dff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima as pm\n",
    "\n",
    "ambulance_train_df['date'] = pd.to_datetime(ambulance_train_df['date'])\n",
    "ambulance_test_df['date'] = pd.to_datetime(ambulance_test_df['date']) \n",
    "\n",
    "arima_model = pm.auto_arima(\n",
    "    ambulance_train_df['calls'],\n",
    "    seasonal=True,\n",
    "    m=52,\n",
    "    d=1,\n",
    "    D=1,\n",
    "    trace=True,\n",
    "    error_action=\"ignore\",\n",
    "    suppress_warnings=True,\n",
    "    stepwise=True\n",
    ")\n",
    "\n",
    "print(arima_model.summary)\n",
    "\n",
    "forecast_arima = arima_model.predict(n_periods=len(ambulance_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd674bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# order=(0, 1, 1)\n",
    "# seasonal_order=(2, 1, 0, 52)\n",
    "sarima_model = SARIMAX(\n",
    "    ambulance_train_df['calls'],\n",
    "    order=(0, 1, 1),\n",
    "    seasonal_order=(2, 1, 0, 52)\n",
    ")\n",
    "\n",
    "results = sarima_model.fit()\n",
    "\n",
    "forecast_arima = results.get_forecast(steps=len(ambulance_test_df))\n",
    "predicted_mean = forecast_arima.predicted_mean\n",
    "predicted_mean.index = ambulance_test_df['date']\n",
    "fitted_values = results.fittedvalues\n",
    "fitted_values.index = ambulance_train_df['date']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(ambulance_train_df['date'], ambulance_train_df['calls'], label='History', color='blue')\n",
    "plt.plot(fitted_values.index, fitted_values, label='Model Fit (Training)', color='orange')\n",
    "plt.plot(predicted_mean.index, predicted_mean, label='SARIMAX Forecast', color='red', linestyle='--')\n",
    "plt.title('Final SARIMAX Forecast: (0,1,1)(2,1,0)[52]')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f164ff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(ambulance_train_df['calls'], fitted_values)\n",
    "print(\"MAE on fitted training data:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f639ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df.loc[\"Training\", \"SARIMAX\"] = 93.8673065514869"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b00aea8",
   "metadata": {},
   "source": [
    "###  Comparison to Actual Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f78220e",
   "metadata": {},
   "source": [
    "MAE was selected as the primary metric because it provides a tangible value in \"calls per week\". For a system like EMS, where resource allocation (# of ambulances) is based on discrete units of demand, MAE offers the most actionable insight into the buffer capacity required to maintain service levels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60615f38",
   "metadata": {},
   "source": [
    "#### Triple Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746743ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.plot(ambulance_test_df['date'], ambulance_test_df['calls'], label='Actual Demand', color='blue')\n",
    "plt.plot(forecast.index, forecast, label='Forecast (Next 1 Year)', color='red', linestyle='--')\n",
    "plt.title(\"Actual Demand vs Forecast (Triple Exponential Smoothing)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"# of Calls\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c67bf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(ambulance_test_df['calls'], forecast.values)\n",
    "print(\"MAE on test data:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b67f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df.loc[\"Test\", \"TES\"] = 139.68399079764032"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca9f89e",
   "metadata": {},
   "source": [
    "#### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d28cf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_values = arima_fitted.forecast(steps=len(ambulance_test_df))\n",
    "forecast_series = pd.Series(forecast_values.values, index=ambulance_test_df['date'])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(ambulance_test_df['date'], ambulance_test_df['calls'], label='Actual Demand', color='blue')\n",
    "plt.plot(forecast_series.index, forecast_series.values, label='SARIMA Forecast', color='red', linestyle='--')\n",
    "plt.title(\"Actual Demand vs Forecast (SARIMAX)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"# of Calls\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87839ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(ambulance_test_df['calls'], forecast_series.values)\n",
    "print(\"MAE on test data:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed63f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df.loc[\"Test\", \"ARIMA\"] = 78.67921835901419"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eb464b",
   "metadata": {},
   "source": [
    "### SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0901631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(ambulance_test_df['date'], ambulance_test_df['calls'], label='Actual Demand', color='blue')\n",
    "plt.plot(predicted_mean.index, predicted_mean, label='SARIMA Forecast', color='red', linestyle='--')\n",
    "plt.title(\"Actual Demand vs Forecast (SARIMAX)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"# of Calls\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d00930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(ambulance_test_df['calls'], predicted_mean.values)\n",
    "print(\"MAE on test data:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a66a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df.loc[\"Test\", \"SARIMAX\"] = 184.0077317600946"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9848d8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0caa44a",
   "metadata": {},
   "source": [
    "#### 1. Which forecasting method was better?\n",
    "\n",
    "ARIMA resulted in a lower MAE with 78.68 compared to TES with a MAE of 139.68 and SARIMAX with a MAE of 184.01.\n",
    "\n",
    "- While the Triple Exponential Smoothing (TES) model fit the training data more closely (Training MAE: 63.01), its error more than doubled in the test phase (Test MAE: 139.68). This indicates that TES overfitted to the specific of the past\n",
    "- The ARIMA model demonstrated very good stability, with its test error (78.68) being nearly identical to its training error (79.65). By producing a more conservative straight-line forecast, it ignored non-repeating noise and captured the true underlying trend better than the more spiky seasonal models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e128e4d",
   "metadata": {},
   "source": [
    "#### 2. Any outliers that impacted forecast accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd719e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the forecast variable from ARIMA\n",
    "test_residuals = ambulance_test_df['calls'] - forecast_series.values\n",
    "\n",
    "Q1_t = test_residuals.quantile(0.25)\n",
    "Q3_t = test_residuals.quantile(0.75)\n",
    "IQR_t = Q3_t - Q1_t\n",
    "\n",
    "lower_t = Q1_t - 1.5 * IQR_t\n",
    "upper_t = Q3_t + 1.5 * IQR_t\n",
    "\n",
    "test_outliers = ambulance_test_df[(test_residuals < lower_t) | (test_residuals > upper_t)]\n",
    "\n",
    "print(\"Outliers found in the 30-week Test Data:\")\n",
    "print(test_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a1ace5",
   "metadata": {},
   "source": [
    "No outliers were found in the 30-week test period using our ARIMA forecast and IQR calculations. This indicates that during the 30 weeks test data, the ambulance call volume followed our ARIMA model's predicted patterns without any extreme or unexplained shocks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e03df27",
   "metadata": {},
   "source": [
    "#### 3. Which method would your recommend using for your particular use case and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b78d5b1",
   "metadata": {},
   "source": [
    "I recommend using the ARIMA model for this ambulance call use case. or Industrial Engineering and resource management (staffing ambulances), a model that generalizes well to new data is critical. The ARIMA model provides a reliable baseline (MAE ~79) regardless of whether it is looking at the past or the future. Relying on the TES model would be riskier, as its performance proved to be highly inconsistent when faced with new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014bbc29",
   "metadata": {},
   "source": [
    "#### 4. What are the strengths and weaknesses of models? What external info. would have helped improve forecast accuracy?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d7047e",
   "metadata": {},
   "source": [
    "ARIMA: \n",
    "- PROS: High stability and generalization, less likely to overfit, works well with smaller test sets\n",
    "- CONS: Produces a flat trend that may miss subtle seasonal oscillations\n",
    "\n",
    "TES:\n",
    "- PROS: Very good at capturing complex seasonal waves qualatatively for historical data.\n",
    "- CONS: Highly prone to overfitting as seen when forecsting and calculating error with test set. Sensitive to historical spikes which it tries to replicate.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
